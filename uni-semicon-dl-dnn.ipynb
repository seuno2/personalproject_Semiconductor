{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdc0297",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:29.993883Z",
     "iopub.status.busy": "2023-04-04T12:45:29.993413Z",
     "iopub.status.idle": "2023-04-04T12:45:30.010844Z",
     "shell.execute_reply": "2023-04-04T12:45:30.009589Z"
    },
    "papermill": {
     "duration": 0.028045,
     "end_time": "2023-04-04T12:45:30.013137",
     "exception": false,
     "start_time": "2023-04-04T12:45:29.985092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/asdasdasd/uci-secom.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09d384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:30.022805Z",
     "iopub.status.busy": "2023-04-04T12:45:30.022440Z",
     "iopub.status.idle": "2023-04-04T12:45:37.747521Z",
     "shell.execute_reply": "2023-04-04T12:45:37.746443Z"
    },
    "papermill": {
     "duration": 7.732856,
     "end_time": "2023-04-04T12:45:37.750396",
     "exception": false,
     "start_time": "2023-04-04T12:45:30.017540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dae88f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:37.760262Z",
     "iopub.status.busy": "2023-04-04T12:45:37.759569Z",
     "iopub.status.idle": "2023-04-04T12:45:37.980858Z",
     "shell.execute_reply": "2023-04-04T12:45:37.979960Z"
    },
    "papermill": {
     "duration": 0.228249,
     "end_time": "2023-04-04T12:45:37.982669",
     "exception": false,
     "start_time": "2023-04-04T12:45:37.754420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>...</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>...</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time        0        1          2          3       4  \\\n",
       "0     2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602   \n",
       "1     2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294   \n",
       "2     2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102   \n",
       "3     2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204   \n",
       "4     2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334   \n",
       "...                   ...      ...      ...        ...        ...     ...   \n",
       "1562  2008-10-16 15:13:00  2899.41  2464.36  2179.7333  3085.3781  1.4843   \n",
       "1563  2008-10-16 20:49:00  3052.31  2522.55  2198.5667  1124.6595  0.8763   \n",
       "1564  2008-10-17 05:26:00  2978.81  2379.78  2206.3000  1110.4967  0.8236   \n",
       "1565  2008-10-17 06:01:00  2894.92  2532.01  2177.0333  1183.7287  1.5726   \n",
       "1566  2008-10-17 06:07:00  2944.92  2450.76  2195.4444  2914.1792  1.5978   \n",
       "\n",
       "          5         6       7       8  ...       581     582     583     584  \\\n",
       "0     100.0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   \n",
       "1     100.0  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   \n",
       "2     100.0   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   \n",
       "3     100.0  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   \n",
       "4     100.0  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045   \n",
       "...     ...       ...     ...     ...  ...       ...     ...     ...     ...   \n",
       "1562  100.0   82.2467  0.1248  1.3424  ...  203.1720  0.4988  0.0143  0.0039   \n",
       "1563  100.0   98.4689  0.1205  1.4333  ...       NaN  0.4975  0.0131  0.0036   \n",
       "1564  100.0   99.4122  0.1208     NaN  ...   43.5231  0.4987  0.0153  0.0041   \n",
       "1565  100.0   98.7978  0.1213  1.4622  ...   93.4941  0.5004  0.0178  0.0038   \n",
       "1566  100.0   85.1011  0.1235     NaN  ...  137.7844  0.4987  0.0181  0.0040   \n",
       "\n",
       "          585     586     587     588       589  Pass/Fail  \n",
       "0      2.3630     NaN     NaN     NaN       NaN         -1  \n",
       "1      4.4447  0.0096  0.0201  0.0060  208.2045         -1  \n",
       "2      3.1745  0.0584  0.0484  0.0148   82.8602          1  \n",
       "3      2.0544  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "4     99.3032  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "...       ...     ...     ...     ...       ...        ...  \n",
       "1562   2.8669  0.0068  0.0138  0.0047  203.1720         -1  \n",
       "1563   2.6238  0.0068  0.0138  0.0047  203.1720         -1  \n",
       "1564   3.0590  0.0197  0.0086  0.0025   43.5231         -1  \n",
       "1565   3.5662  0.0262  0.0245  0.0075   93.4941         -1  \n",
       "1566   3.6275  0.0117  0.0162  0.0045  137.7844         -1  \n",
       "\n",
       "[1567 rows x 592 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/asdasdasd/uci-secom.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966332d",
   "metadata": {
    "papermill": {
     "duration": 0.003632,
     "end_time": "2023-04-04T12:45:37.990401",
     "exception": false,
     "start_time": "2023-04-04T12:45:37.986769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Collinearity Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409ee954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:37.999098Z",
     "iopub.status.busy": "2023-04-04T12:45:37.998802Z",
     "iopub.status.idle": "2023-04-04T12:45:38.005706Z",
     "shell.execute_reply": "2023-04-04T12:45:38.004913Z"
    },
    "papermill": {
     "duration": 0.013204,
     "end_time": "2023-04-04T12:45:38.007412",
     "exception": false,
     "start_time": "2023-04-04T12:45:37.994208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_collinear_features(x, threshold):\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "    \n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            if val >= threshold:\n",
    "                print(col.values[0], '|', row.values[0], '|', round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "                \n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0373aaa",
   "metadata": {
    "papermill": {
     "duration": 0.003738,
     "end_time": "2023-04-04T12:45:38.015055",
     "exception": false,
     "start_time": "2023-04-04T12:45:38.011317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38595ec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:38.023993Z",
     "iopub.status.busy": "2023-04-04T12:45:38.023693Z",
     "iopub.status.idle": "2023-04-04T12:45:38.034770Z",
     "shell.execute_reply": "2023-04-04T12:45:38.034045Z"
    },
    "papermill": {
     "duration": 0.017432,
     "end_time": "2023-04-04T12:45:38.036464",
     "exception": false,
     "start_time": "2023-04-04T12:45:38.019032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(data, th = 0.95):\n",
    "    \n",
    "    data = data.replace(np.NaN, 0)\n",
    "    data = remove_collinear_features(data, th)\n",
    "    data = data.drop(columns = ['Time'], axis = 1)\n",
    "    \n",
    "    # - 항상 같은 값인 column 삭제 \n",
    "    dupList = []\n",
    "    for col in data.columns:\n",
    "        if len(data.loc[:,col].value_counts()) == 1:\n",
    "            dupList.append(col)\n",
    "    \n",
    "    data = data.drop(dupList, axis = 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def split_x_y(data):\n",
    "    \n",
    "    x = data.iloc[:, :306]\n",
    "    y = data['Pass/Fail']\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def train_val_test_split(x, y, random_state = 42):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = random_state)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = 0.5, random_state = random_state)\n",
    "    \n",
    "    print('x_train shape :', x_train.shape)\n",
    "    print('y_train shape :', y_train.shape)\n",
    "\n",
    "    print('x_test shape :', x_test.shape)\n",
    "    print('y_test shape :', y_test.shape)\n",
    "\n",
    "    print('x_val shape :', x_val.shape)\n",
    "    print('y_val shape :', y_val.shape)\n",
    "    \n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "def standardization(x_train, x_val, x_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x_train)\n",
    "    x_train = sc.transform(x_train)\n",
    "    x_val = sc.transform(x_val)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "def y_change(y):\n",
    "    y_np = np.array(y)\n",
    "    y_np = np.where(y_np == -1, 0, 1)\n",
    "    return y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c0ed9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:38.045533Z",
     "iopub.status.busy": "2023-04-04T12:45:38.045250Z",
     "iopub.status.idle": "2023-04-04T12:45:52.664654Z",
     "shell.execute_reply": "2023-04-04T12:45:52.663769Z"
    },
    "papermill": {
     "duration": 14.626803,
     "end_time": "2023-04-04T12:45:52.667272",
     "exception": false,
     "start_time": "2023-04-04T12:45:38.040469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | 2 | 0.99\n",
      "27 | 25 | 0.98\n",
      "38 | 37 | 0.97\n",
      "49 | 42 | 1.0\n",
      "50 | 46 | 0.97\n",
      "54 | 53 | 1.0\n",
      "55 | 53 | 0.95\n",
      "56 | 53 | 0.98\n",
      "56 | 54 | 0.97\n",
      "56 | 55 | 0.96\n",
      "57 | 53 | 0.97\n",
      "57 | 54 | 0.96\n",
      "57 | 55 | 0.98\n",
      "57 | 56 | 0.99\n",
      "58 | 56 | 0.96\n",
      "66 | 60 | 0.97\n",
      "69 | 60 | 0.96\n",
      "69 | 66 | 0.97\n",
      "70 | 60 | 0.97\n",
      "70 | 66 | 0.99\n",
      "70 | 69 | 0.97\n",
      "73 | 72 | 0.98\n",
      "96 | 94 | 0.96\n",
      "104 | 99 | 0.99\n",
      "105 | 92 | 0.99\n",
      "106 | 93 | 0.99\n",
      "110 | 109 | 1.0\n",
      "111 | 109 | 1.0\n",
      "111 | 110 | 1.0\n",
      "123 | 121 | 1.0\n",
      "124 | 121 | 1.0\n",
      "124 | 123 | 1.0\n",
      "127 | 122 | 0.97\n",
      "131 | 121 | 1.0\n",
      "131 | 123 | 0.99\n",
      "131 | 124 | 0.99\n",
      "133 | 132 | 0.95\n",
      "140 | 4 | 1.0\n",
      "148 | 16 | 0.96\n",
      "152 | 16 | 0.96\n",
      "152 | 148 | 0.99\n",
      "165 | 164 | 0.96\n",
      "174 | 172 | 1.0\n",
      "206 | 74 | 1.0\n",
      "209 | 74 | 1.0\n",
      "209 | 206 | 1.0\n",
      "220 | 85 | 0.97\n",
      "246 | 244 | 0.96\n",
      "246 | 245 | 0.98\n",
      "249 | 114 | 0.98\n",
      "252 | 117 | 0.99\n",
      "271 | 136 | 0.97\n",
      "272 | 137 | 0.98\n",
      "274 | 139 | 0.99\n",
      "275 | 4 | 1.0\n",
      "275 | 140 | 1.0\n",
      "277 | 142 | 0.98\n",
      "279 | 144 | 0.98\n",
      "280 | 145 | 0.96\n",
      "281 | 146 | 0.95\n",
      "282 | 147 | 1.0\n",
      "283 | 16 | 0.96\n",
      "283 | 148 | 1.0\n",
      "283 | 152 | 0.99\n",
      "285 | 150 | 0.97\n",
      "286 | 151 | 0.99\n",
      "287 | 16 | 0.96\n",
      "287 | 148 | 0.99\n",
      "287 | 152 | 1.0\n",
      "287 | 283 | 0.99\n",
      "288 | 153 | 1.0\n",
      "289 | 154 | 0.99\n",
      "290 | 155 | 0.95\n",
      "291 | 156 | 0.99\n",
      "292 | 157 | 1.0\n",
      "293 | 158 | 0.99\n",
      "294 | 159 | 0.99\n",
      "295 | 160 | 1.0\n",
      "296 | 161 | 0.99\n",
      "297 | 162 | 0.99\n",
      "298 | 163 | 0.99\n",
      "299 | 164 | 1.0\n",
      "299 | 165 | 0.96\n",
      "300 | 164 | 0.97\n",
      "300 | 165 | 1.0\n",
      "300 | 299 | 0.97\n",
      "301 | 166 | 0.96\n",
      "302 | 167 | 0.98\n",
      "303 | 168 | 0.96\n",
      "304 | 169 | 0.98\n",
      "305 | 170 | 0.96\n",
      "306 | 171 | 0.99\n",
      "307 | 172 | 0.96\n",
      "307 | 174 | 0.96\n",
      "308 | 173 | 0.96\n",
      "309 | 172 | 0.96\n",
      "309 | 174 | 0.96\n",
      "309 | 307 | 1.0\n",
      "310 | 175 | 0.96\n",
      "311 | 176 | 0.98\n",
      "312 | 177 | 1.0\n",
      "317 | 181 | 0.96\n",
      "318 | 182 | 0.98\n",
      "319 | 183 | 0.98\n",
      "320 | 184 | 0.99\n",
      "321 | 185 | 0.99\n",
      "323 | 187 | 0.99\n",
      "324 | 188 | 0.98\n",
      "332 | 196 | 0.96\n",
      "333 | 197 | 0.98\n",
      "334 | 198 | 0.99\n",
      "335 | 199 | 0.96\n",
      "335 | 332 | 0.96\n",
      "338 | 202 | 0.99\n",
      "339 | 203 | 0.98\n",
      "340 | 204 | 0.99\n",
      "341 | 205 | 0.99\n",
      "342 | 74 | 1.0\n",
      "342 | 206 | 1.0\n",
      "342 | 209 | 1.0\n",
      "343 | 207 | 0.98\n",
      "344 | 208 | 0.96\n",
      "346 | 345 | 0.98\n",
      "347 | 74 | 1.0\n",
      "347 | 206 | 1.0\n",
      "347 | 209 | 1.0\n",
      "347 | 342 | 1.0\n",
      "348 | 210 | 0.95\n",
      "349 | 211 | 0.99\n",
      "350 | 212 | 0.99\n",
      "351 | 213 | 1.0\n",
      "352 | 214 | 0.98\n",
      "353 | 215 | 0.98\n",
      "354 | 216 | 0.97\n",
      "355 | 217 | 0.99\n",
      "356 | 218 | 0.95\n",
      "357 | 219 | 0.98\n",
      "358 | 85 | 0.99\n",
      "358 | 220 | 0.99\n",
      "359 | 221 | 0.98\n",
      "360 | 222 | 0.99\n",
      "361 | 223 | 0.98\n",
      "362 | 224 | 1.0\n",
      "363 | 225 | 0.97\n",
      "365 | 227 | 0.97\n",
      "366 | 228 | 0.97\n",
      "376 | 238 | 0.97\n",
      "377 | 239 | 0.96\n",
      "382 | 244 | 1.0\n",
      "382 | 246 | 0.96\n",
      "383 | 245 | 1.0\n",
      "383 | 246 | 0.98\n",
      "384 | 244 | 0.96\n",
      "384 | 245 | 0.98\n",
      "384 | 246 | 1.0\n",
      "384 | 382 | 0.96\n",
      "384 | 383 | 0.98\n",
      "386 | 248 | 1.0\n",
      "387 | 114 | 0.98\n",
      "387 | 249 | 1.0\n",
      "388 | 250 | 0.97\n",
      "389 | 251 | 1.0\n",
      "390 | 117 | 0.99\n",
      "390 | 252 | 1.0\n",
      "391 | 253 | 0.99\n",
      "392 | 254 | 0.99\n",
      "393 | 255 | 0.99\n",
      "405 | 267 | 0.99\n",
      "406 | 268 | 0.97\n",
      "407 | 269 | 0.96\n",
      "408 | 135 | 1.0\n",
      "409 | 136 | 1.0\n",
      "409 | 271 | 0.97\n",
      "410 | 137 | 1.0\n",
      "410 | 272 | 0.97\n",
      "411 | 138 | 1.0\n",
      "415 | 142 | 0.99\n",
      "415 | 277 | 0.97\n",
      "416 | 143 | 1.0\n",
      "417 | 144 | 0.99\n",
      "417 | 279 | 0.97\n",
      "420 | 147 | 1.0\n",
      "420 | 282 | 1.0\n",
      "421 | 16 | 0.95\n",
      "421 | 148 | 1.0\n",
      "421 | 152 | 0.98\n",
      "421 | 154 | 0.95\n",
      "421 | 283 | 1.0\n",
      "421 | 287 | 0.98\n",
      "421 | 289 | 0.95\n",
      "424 | 151 | 0.98\n",
      "424 | 286 | 0.97\n",
      "425 | 148 | 0.96\n",
      "425 | 152 | 0.98\n",
      "425 | 283 | 0.96\n",
      "425 | 287 | 0.97\n",
      "425 | 421 | 0.95\n",
      "426 | 153 | 1.0\n",
      "426 | 288 | 0.99\n",
      "427 | 148 | 0.95\n",
      "427 | 154 | 1.0\n",
      "427 | 283 | 0.95\n",
      "427 | 289 | 0.99\n",
      "427 | 421 | 0.97\n",
      "428 | 155 | 1.0\n",
      "428 | 290 | 0.96\n",
      "429 | 156 | 1.0\n",
      "429 | 291 | 0.99\n",
      "435 | 430 | 0.95\n",
      "435 | 434 | 0.99\n",
      "436 | 430 | 0.95\n",
      "436 | 434 | 0.99\n",
      "436 | 435 | 1.0\n",
      "437 | 166 | 0.99\n",
      "440 | 169 | 1.0\n",
      "440 | 304 | 0.98\n",
      "441 | 170 | 1.0\n",
      "441 | 305 | 0.95\n",
      "442 | 171 | 0.97\n",
      "442 | 306 | 0.96\n",
      "443 | 172 | 1.0\n",
      "443 | 174 | 1.0\n",
      "443 | 307 | 0.96\n",
      "443 | 309 | 0.96\n",
      "444 | 173 | 0.99\n",
      "444 | 308 | 0.95\n",
      "445 | 172 | 1.0\n",
      "445 | 174 | 1.0\n",
      "445 | 307 | 0.96\n",
      "445 | 309 | 0.96\n",
      "445 | 443 | 0.99\n",
      "446 | 175 | 1.0\n",
      "446 | 310 | 0.96\n",
      "447 | 176 | 1.0\n",
      "447 | 311 | 0.98\n",
      "448 | 177 | 1.0\n",
      "448 | 312 | 1.0\n",
      "452 | 180 | 0.99\n",
      "453 | 181 | 1.0\n",
      "453 | 317 | 0.96\n",
      "454 | 182 | 0.99\n",
      "454 | 318 | 0.97\n",
      "455 | 183 | 1.0\n",
      "455 | 319 | 0.98\n",
      "456 | 184 | 0.97\n",
      "456 | 320 | 0.96\n",
      "457 | 185 | 1.0\n",
      "457 | 321 | 0.99\n",
      "459 | 187 | 1.0\n",
      "459 | 323 | 0.99\n",
      "467 | 195 | 1.0\n",
      "467 | 331 | 0.95\n",
      "469 | 197 | 1.0\n",
      "469 | 333 | 0.99\n",
      "470 | 198 | 1.0\n",
      "470 | 334 | 0.98\n",
      "475 | 203 | 1.0\n",
      "475 | 339 | 0.99\n",
      "477 | 205 | 0.99\n",
      "477 | 341 | 0.99\n",
      "478 | 74 | 1.0\n",
      "478 | 206 | 1.0\n",
      "478 | 209 | 1.0\n",
      "478 | 342 | 1.0\n",
      "478 | 347 | 1.0\n",
      "479 | 207 | 1.0\n",
      "479 | 343 | 0.97\n",
      "490 | 218 | 0.98\n",
      "491 | 219 | 1.0\n",
      "491 | 357 | 0.97\n",
      "492 | 85 | 0.97\n",
      "492 | 220 | 1.0\n",
      "492 | 358 | 0.99\n",
      "493 | 221 | 1.0\n",
      "493 | 359 | 0.98\n",
      "494 | 222 | 1.0\n",
      "494 | 360 | 1.0\n",
      "495 | 223 | 1.0\n",
      "495 | 361 | 0.97\n",
      "497 | 225 | 0.99\n",
      "497 | 363 | 0.97\n",
      "516 | 244 | 1.0\n",
      "516 | 246 | 0.96\n",
      "516 | 382 | 1.0\n",
      "516 | 384 | 0.96\n",
      "517 | 244 | 0.95\n",
      "517 | 245 | 1.0\n",
      "517 | 246 | 0.98\n",
      "517 | 382 | 0.95\n",
      "517 | 383 | 1.0\n",
      "517 | 384 | 0.98\n",
      "517 | 516 | 0.95\n",
      "518 | 244 | 0.96\n",
      "518 | 245 | 0.98\n",
      "518 | 246 | 1.0\n",
      "518 | 382 | 0.96\n",
      "518 | 383 | 0.98\n",
      "518 | 384 | 1.0\n",
      "518 | 516 | 0.96\n",
      "518 | 517 | 0.98\n",
      "519 | 247 | 0.97\n",
      "519 | 385 | 0.96\n",
      "520 | 248 | 1.0\n",
      "520 | 386 | 1.0\n",
      "522 | 250 | 0.99\n",
      "522 | 388 | 0.96\n",
      "523 | 251 | 1.0\n",
      "523 | 389 | 1.0\n",
      "524 | 117 | 0.98\n",
      "524 | 252 | 1.0\n",
      "524 | 390 | 1.0\n",
      "525 | 253 | 1.0\n",
      "525 | 391 | 0.99\n",
      "526 | 254 | 1.0\n",
      "526 | 392 | 0.99\n",
      "527 | 255 | 1.0\n",
      "527 | 393 | 0.98\n",
      "539 | 267 | 1.0\n",
      "539 | 405 | 0.99\n",
      "540 | 268 | 1.0\n",
      "540 | 406 | 0.97\n",
      "541 | 269 | 0.97\n",
      "545 | 543 | 0.99\n",
      "548 | 547 | 0.99\n",
      "552 | 549 | 1.0\n",
      "553 | 550 | 0.99\n",
      "554 | 551 | 1.0\n",
      "556 | 550 | 1.0\n",
      "556 | 553 | 0.99\n",
      "557 | 551 | 1.0\n",
      "557 | 554 | 1.0\n",
      "561 | 559 | 0.98\n",
      "566 | 564 | 0.99\n",
      "567 | 565 | 0.99\n",
      "568 | 564 | 1.0\n",
      "568 | 566 | 0.99\n",
      "569 | 565 | 0.96\n",
      "569 | 567 | 0.96\n",
      "574 | 572 | 0.99\n",
      "575 | 573 | 0.98\n",
      "576 | 572 | 0.99\n",
      "576 | 574 | 0.99\n",
      "577 | 573 | 0.96\n",
      "580 | 579 | 0.99\n",
      "584 | 583 | 0.99\n",
      "585 | 583 | 1.0\n",
      "585 | 584 | 1.0\n",
      "588 | 587 | 0.97\n",
      "x_train shape : (1253, 269)\n",
      "y_train shape : (1253,)\n",
      "x_test shape : (157, 269)\n",
      "y_test shape : (157,)\n",
      "x_val shape : (157, 269)\n",
      "y_val shape : (157,)\n"
     ]
    }
   ],
   "source": [
    "data_pre = data_preprocess(data)\n",
    "X, y = split_x_y(data_pre)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y)\n",
    "X_train, X_val, X_test = standardization(X_train, X_val, X_test)\n",
    "y_train, y_val, y_test = y_change(y_train), y_change(y_val), y_change(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189dd76",
   "metadata": {
    "papermill": {
     "duration": 0.006802,
     "end_time": "2023-04-04T12:45:52.681317",
     "exception": false,
     "start_time": "2023-04-04T12:45:52.674515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tensorflos Keras Modeling\n",
    "- 32-16-8-4-2 1d layers\n",
    "- Activation : ReLU \n",
    "- Loss function : cross-entropy / Optimizer : Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3106bd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:52.696683Z",
     "iopub.status.busy": "2023-04-04T12:45:52.696328Z",
     "iopub.status.idle": "2023-04-04T12:45:52.836443Z",
     "shell.execute_reply": "2023-04-04T12:45:52.835638Z"
    },
    "papermill": {
     "duration": 0.150491,
     "end_time": "2023-04-04T12:45:52.838761",
     "exception": false,
     "start_time": "2023-04-04T12:45:52.688270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu',input_shape = (X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'softmax'),    \n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066e517c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:45:52.854077Z",
     "iopub.status.busy": "2023-04-04T12:45:52.853554Z",
     "iopub.status.idle": "2023-04-04T12:46:02.926577Z",
     "shell.execute_reply": "2023-04-04T12:46:02.925599Z"
    },
    "papermill": {
     "duration": 10.083133,
     "end_time": "2023-04-04T12:46:02.928823",
     "exception": false,
     "start_time": "2023-04-04T12:45:52.845690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 6ms/step - loss: 0.4266 - val_loss: 0.2472\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1925 - val_loss: 0.1746\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1445\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.1245\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.1136\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.1046\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0989\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0880\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0840\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0811\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0767\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0686\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0656\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0632\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0628\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0601\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0587\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0563\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0549\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.8707e-04 - val_loss: 0.0536\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.1123e-04 - val_loss: 0.0512\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.8471e-04 - val_loss: 0.0498\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.8608e-04 - val_loss: 0.0496\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.0132e-04 - val_loss: 0.0486\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.3511e-04 - val_loss: 0.0470\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8397e-04 - val_loss: 0.0463\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.3848e-04 - val_loss: 0.0449\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.0080e-04 - val_loss: 0.0439\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.6997e-04 - val_loss: 0.0433\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3012e-04 - val_loss: 0.0450\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0785e-04 - val_loss: 0.0443\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8678e-04 - val_loss: 0.0428\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7004e-04 - val_loss: 0.0420\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5521e-04 - val_loss: 0.0411\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4270e-04 - val_loss: 0.0402\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3110e-04 - val_loss: 0.0394\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2086e-04 - val_loss: 0.0386\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1190e-04 - val_loss: 0.0386\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0410e-04 - val_loss: 0.0378\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.6333e-05 - val_loss: 0.0369\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.0005e-05 - val_loss: 0.0367\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.3705e-05 - val_loss: 0.0361\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.8240e-05 - val_loss: 0.0357\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.3147e-05 - val_loss: 0.0352\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.8508e-05 - val_loss: 0.0346\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.4323e-05 - val_loss: 0.0341\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.0088e-05 - val_loss: 0.0337\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.6677e-05 - val_loss: 0.0334\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.3221e-05 - val_loss: 0.0325\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 5.0331e-05 - val_loss: 0.0319\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.7383e-05 - val_loss: 0.0313\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.4790e-05 - val_loss: 0.0309\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 4.2502e-05 - val_loss: 0.0306\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 4.0225e-05 - val_loss: 0.0305\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.8152e-05 - val_loss: 0.0299\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.6216e-05 - val_loss: 0.0295\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4503e-05 - val_loss: 0.0292\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.2607e-05 - val_loss: 0.0284\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.1184e-05 - val_loss: 0.0282\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.9561e-05 - val_loss: 0.0276\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.8184e-05 - val_loss: 0.0273\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.6914e-05 - val_loss: 0.0271\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.5653e-05 - val_loss: 0.0268\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.4505e-05 - val_loss: 0.0264\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.3434e-05 - val_loss: 0.0262\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.2455e-05 - val_loss: 0.0259\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.1462e-05 - val_loss: 0.0254\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 2.0582e-05 - val_loss: 0.0253\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.9683e-05 - val_loss: 0.0248\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8860e-05 - val_loss: 0.0243\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.8087e-05 - val_loss: 0.0244\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.7356e-05 - val_loss: 0.0240\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.6679e-05 - val_loss: 0.0236\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5969e-05 - val_loss: 0.0233\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.5362e-05 - val_loss: 0.0231\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4765e-05 - val_loss: 0.0228\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.4204e-05 - val_loss: 0.0225\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3648e-05 - val_loss: 0.0220\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3135e-05 - val_loss: 0.0219\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2661e-05 - val_loss: 0.0215\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.2183e-05 - val_loss: 0.0214\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.1601e-05 - val_loss: 0.0218\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.1156e-05 - val_loss: 0.0214\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0762e-05 - val_loss: 0.0213\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.0375e-05 - val_loss: 0.0209\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0014e-05 - val_loss: 0.0206\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.6663e-06 - val_loss: 0.0203\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 9.3140e-06 - val_loss: 0.0200\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.9988e-06 - val_loss: 0.0198\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.6855e-06 - val_loss: 0.0194\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.4142e-06 - val_loss: 0.0192\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.1259e-06 - val_loss: 0.0189\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.8467e-06 - val_loss: 0.0187\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.5737e-06 - val_loss: 0.0187\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.3205e-06 - val_loss: 0.0185\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.0827e-06 - val_loss: 0.0181\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.8620e-06 - val_loss: 0.0180\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.6461e-06 - val_loss: 0.0177\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.4474e-06 - val_loss: 0.0177\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 6.2323e-06 - val_loss: 0.0173\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81bc53",
   "metadata": {
    "papermill": {
     "duration": 0.027717,
     "end_time": "2023-04-04T12:46:02.985021",
     "exception": false,
     "start_time": "2023-04-04T12:46:02.957304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05aabb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:46:03.043683Z",
     "iopub.status.busy": "2023-04-04T12:46:03.043250Z",
     "iopub.status.idle": "2023-04-04T12:46:03.051670Z",
     "shell.execute_reply": "2023-04-04T12:46:03.050599Z"
    },
    "papermill": {
     "duration": 0.040132,
     "end_time": "2023-04-04T12:46:03.053531",
     "exception": false,
     "start_time": "2023-04-04T12:46:03.013399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_metric(x_test, model):\n",
    "    y_pred = np.argmax(model.predict(x_test), axis = 1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    tp = cm[0,0]\n",
    "    fn = cm[0,1]\n",
    "    fp = cm[1,0]\n",
    "    tn = cm[1,1]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*precision*recall / (precision + recall)\n",
    "    acc = (tp+tn) / (tp+fn+fp+tn)\n",
    "    print('precision : ', precision)\n",
    "    print('recall : ', recall)\n",
    "    print('f1 : ', f1)\n",
    "    print('acc : ', acc)\n",
    "    \n",
    "    return cm, precision, recall, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15167317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:46:03.110891Z",
     "iopub.status.busy": "2023-04-04T12:46:03.110551Z",
     "iopub.status.idle": "2023-04-04T12:46:03.248926Z",
     "shell.execute_reply": "2023-04-04T12:46:03.247741Z"
    },
    "papermill": {
     "duration": 0.169566,
     "end_time": "2023-04-04T12:46:03.251057",
     "exception": false,
     "start_time": "2023-04-04T12:46:03.081491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "[[140   1]\n",
      " [  6  10]]\n",
      "precision :  0.958904109589041\n",
      "recall :  0.9929078014184397\n",
      "f1 :  0.975609756097561\n",
      "acc :  0.9554140127388535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[140,   1],\n",
       "        [  6,  10]]),\n",
       " 0.958904109589041,\n",
       " 0.9929078014184397,\n",
       " 0.975609756097561,\n",
       " 0.9554140127388535)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metric(X_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0dbe2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:46:03.308902Z",
     "iopub.status.busy": "2023-04-04T12:46:03.308558Z",
     "iopub.status.idle": "2023-04-04T12:46:03.569621Z",
     "shell.execute_reply": "2023-04-04T12:46:03.568945Z"
    },
    "papermill": {
     "duration": 0.29218,
     "end_time": "2023-04-04T12:46:03.571426",
     "exception": false,
     "start_time": "2023-04-04T12:46:03.279246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis =1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm/np.sum(cm),fmt='.2%', annot = True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.378347,
   "end_time": "2023-04-04T12:46:06.462553",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-04T12:45:22.084206",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
