{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fe2ba8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-04T12:41:52.648443Z",
     "iopub.status.busy": "2023-04-04T12:41:52.647623Z",
     "iopub.status.idle": "2023-04-04T12:41:52.669435Z",
     "shell.execute_reply": "2023-04-04T12:41:52.667987Z"
    },
    "papermill": {
     "duration": 0.036207,
     "end_time": "2023-04-04T12:41:52.672576",
     "exception": false,
     "start_time": "2023-04-04T12:41:52.636369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/asdasdasd/uci-secom.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18f6c27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:41:52.684168Z",
     "iopub.status.busy": "2023-04-04T12:41:52.683686Z",
     "iopub.status.idle": "2023-04-04T12:42:02.664106Z",
     "shell.execute_reply": "2023-04-04T12:42:02.662380Z"
    },
    "papermill": {
     "duration": 9.98955,
     "end_time": "2023-04-04T12:42:02.667150",
     "exception": false,
     "start_time": "2023-04-04T12:41:52.677600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7f5a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:02.678963Z",
     "iopub.status.busy": "2023-04-04T12:42:02.678072Z",
     "iopub.status.idle": "2023-04-04T12:42:03.001145Z",
     "shell.execute_reply": "2023-04-04T12:42:02.998096Z"
    },
    "papermill": {
     "duration": 0.332329,
     "end_time": "2023-04-04T12:42:03.004294",
     "exception": false,
     "start_time": "2023-04-04T12:42:02.671965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>...</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>...</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time        0        1          2          3       4  \\\n",
       "0     2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602   \n",
       "1     2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294   \n",
       "2     2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102   \n",
       "3     2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204   \n",
       "4     2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334   \n",
       "...                   ...      ...      ...        ...        ...     ...   \n",
       "1562  2008-10-16 15:13:00  2899.41  2464.36  2179.7333  3085.3781  1.4843   \n",
       "1563  2008-10-16 20:49:00  3052.31  2522.55  2198.5667  1124.6595  0.8763   \n",
       "1564  2008-10-17 05:26:00  2978.81  2379.78  2206.3000  1110.4967  0.8236   \n",
       "1565  2008-10-17 06:01:00  2894.92  2532.01  2177.0333  1183.7287  1.5726   \n",
       "1566  2008-10-17 06:07:00  2944.92  2450.76  2195.4444  2914.1792  1.5978   \n",
       "\n",
       "          5         6       7       8  ...       581     582     583     584  \\\n",
       "0     100.0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   \n",
       "1     100.0  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   \n",
       "2     100.0   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   \n",
       "3     100.0  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   \n",
       "4     100.0  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045   \n",
       "...     ...       ...     ...     ...  ...       ...     ...     ...     ...   \n",
       "1562  100.0   82.2467  0.1248  1.3424  ...  203.1720  0.4988  0.0143  0.0039   \n",
       "1563  100.0   98.4689  0.1205  1.4333  ...       NaN  0.4975  0.0131  0.0036   \n",
       "1564  100.0   99.4122  0.1208     NaN  ...   43.5231  0.4987  0.0153  0.0041   \n",
       "1565  100.0   98.7978  0.1213  1.4622  ...   93.4941  0.5004  0.0178  0.0038   \n",
       "1566  100.0   85.1011  0.1235     NaN  ...  137.7844  0.4987  0.0181  0.0040   \n",
       "\n",
       "          585     586     587     588       589  Pass/Fail  \n",
       "0      2.3630     NaN     NaN     NaN       NaN         -1  \n",
       "1      4.4447  0.0096  0.0201  0.0060  208.2045         -1  \n",
       "2      3.1745  0.0584  0.0484  0.0148   82.8602          1  \n",
       "3      2.0544  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "4     99.3032  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "...       ...     ...     ...     ...       ...        ...  \n",
       "1562   2.8669  0.0068  0.0138  0.0047  203.1720         -1  \n",
       "1563   2.6238  0.0068  0.0138  0.0047  203.1720         -1  \n",
       "1564   3.0590  0.0197  0.0086  0.0025   43.5231         -1  \n",
       "1565   3.5662  0.0262  0.0245  0.0075   93.4941         -1  \n",
       "1566   3.6275  0.0117  0.0162  0.0045  137.7844         -1  \n",
       "\n",
       "[1567 rows x 592 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/asdasdasd/uci-secom.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee57e8",
   "metadata": {
    "papermill": {
     "duration": 0.004771,
     "end_time": "2023-04-04T12:42:03.015444",
     "exception": false,
     "start_time": "2023-04-04T12:42:03.010673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Collinearity Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe4aee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:03.027665Z",
     "iopub.status.busy": "2023-04-04T12:42:03.027174Z",
     "iopub.status.idle": "2023-04-04T12:42:03.037098Z",
     "shell.execute_reply": "2023-04-04T12:42:03.035514Z"
    },
    "papermill": {
     "duration": 0.019015,
     "end_time": "2023-04-04T12:42:03.039603",
     "exception": false,
     "start_time": "2023-04-04T12:42:03.020588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_collinear_features(x, threshold):\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "    \n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            if val >= threshold:\n",
    "                print(col.values[0], '|', row.values[0], '|', round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "                \n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5e626",
   "metadata": {
    "papermill": {
     "duration": 0.004812,
     "end_time": "2023-04-04T12:42:03.049474",
     "exception": false,
     "start_time": "2023-04-04T12:42:03.044662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cc54c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:03.061941Z",
     "iopub.status.busy": "2023-04-04T12:42:03.061377Z",
     "iopub.status.idle": "2023-04-04T12:42:03.075221Z",
     "shell.execute_reply": "2023-04-04T12:42:03.073742Z"
    },
    "papermill": {
     "duration": 0.023488,
     "end_time": "2023-04-04T12:42:03.077956",
     "exception": false,
     "start_time": "2023-04-04T12:42:03.054468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocess(data, th = 0.95):\n",
    "    \n",
    "    data = data.replace(np.NaN, 0)\n",
    "    data = remove_collinear_features(data, th)\n",
    "    data = data.drop(columns = ['Time'], axis = 1)\n",
    "    \n",
    "    # - 항상 같은 값인 column 삭제 \n",
    "    dupList = []\n",
    "    for col in data.columns:\n",
    "        if len(data.loc[:,col].value_counts()) == 1:\n",
    "            dupList.append(col)\n",
    "    \n",
    "    data = data.drop(dupList, axis = 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def split_x_y(data):\n",
    "    \n",
    "    x = data.iloc[:, :306]\n",
    "    y = data['Pass/Fail']\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def train_val_test_split(x, y, random_state = 42):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = random_state)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = 0.5, random_state = random_state)\n",
    "    \n",
    "    print('x_train shape :', x_train.shape)\n",
    "    print('y_train shape :', y_train.shape)\n",
    "\n",
    "    print('x_test shape :', x_test.shape)\n",
    "    print('y_test shape :', y_test.shape)\n",
    "\n",
    "    print('x_val shape :', x_val.shape)\n",
    "    print('y_val shape :', y_val.shape)\n",
    "    \n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "def standardization(x_train, x_val, x_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x_train)\n",
    "    x_train = sc.transform(x_train)\n",
    "    x_val = sc.transform(x_val)\n",
    "    x_test = sc.transform(x_test)\n",
    "    \n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "def y_change(y):\n",
    "    y_np = np.array(y)\n",
    "    y_np = np.where(y_np == -1, 0, 1)\n",
    "    return y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7b3409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:03.090236Z",
     "iopub.status.busy": "2023-04-04T12:42:03.089782Z",
     "iopub.status.idle": "2023-04-04T12:42:20.085181Z",
     "shell.execute_reply": "2023-04-04T12:42:20.083273Z"
    },
    "papermill": {
     "duration": 17.005027,
     "end_time": "2023-04-04T12:42:20.088066",
     "exception": false,
     "start_time": "2023-04-04T12:42:03.083039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | 2 | 0.99\n",
      "27 | 25 | 0.98\n",
      "38 | 37 | 0.97\n",
      "49 | 42 | 1.0\n",
      "50 | 46 | 0.97\n",
      "54 | 53 | 1.0\n",
      "55 | 53 | 0.95\n",
      "56 | 53 | 0.98\n",
      "56 | 54 | 0.97\n",
      "56 | 55 | 0.96\n",
      "57 | 53 | 0.97\n",
      "57 | 54 | 0.96\n",
      "57 | 55 | 0.98\n",
      "57 | 56 | 0.99\n",
      "58 | 56 | 0.96\n",
      "66 | 60 | 0.97\n",
      "69 | 60 | 0.96\n",
      "69 | 66 | 0.97\n",
      "70 | 60 | 0.97\n",
      "70 | 66 | 0.99\n",
      "70 | 69 | 0.97\n",
      "73 | 72 | 0.98\n",
      "96 | 94 | 0.96\n",
      "104 | 99 | 0.99\n",
      "105 | 92 | 0.99\n",
      "106 | 93 | 0.99\n",
      "110 | 109 | 1.0\n",
      "111 | 109 | 1.0\n",
      "111 | 110 | 1.0\n",
      "123 | 121 | 1.0\n",
      "124 | 121 | 1.0\n",
      "124 | 123 | 1.0\n",
      "127 | 122 | 0.97\n",
      "131 | 121 | 1.0\n",
      "131 | 123 | 0.99\n",
      "131 | 124 | 0.99\n",
      "133 | 132 | 0.95\n",
      "140 | 4 | 1.0\n",
      "148 | 16 | 0.96\n",
      "152 | 16 | 0.96\n",
      "152 | 148 | 0.99\n",
      "165 | 164 | 0.96\n",
      "174 | 172 | 1.0\n",
      "206 | 74 | 1.0\n",
      "209 | 74 | 1.0\n",
      "209 | 206 | 1.0\n",
      "220 | 85 | 0.97\n",
      "246 | 244 | 0.96\n",
      "246 | 245 | 0.98\n",
      "249 | 114 | 0.98\n",
      "252 | 117 | 0.99\n",
      "271 | 136 | 0.97\n",
      "272 | 137 | 0.98\n",
      "274 | 139 | 0.99\n",
      "275 | 4 | 1.0\n",
      "275 | 140 | 1.0\n",
      "277 | 142 | 0.98\n",
      "279 | 144 | 0.98\n",
      "280 | 145 | 0.96\n",
      "281 | 146 | 0.95\n",
      "282 | 147 | 1.0\n",
      "283 | 16 | 0.96\n",
      "283 | 148 | 1.0\n",
      "283 | 152 | 0.99\n",
      "285 | 150 | 0.97\n",
      "286 | 151 | 0.99\n",
      "287 | 16 | 0.96\n",
      "287 | 148 | 0.99\n",
      "287 | 152 | 1.0\n",
      "287 | 283 | 0.99\n",
      "288 | 153 | 1.0\n",
      "289 | 154 | 0.99\n",
      "290 | 155 | 0.95\n",
      "291 | 156 | 0.99\n",
      "292 | 157 | 1.0\n",
      "293 | 158 | 0.99\n",
      "294 | 159 | 0.99\n",
      "295 | 160 | 1.0\n",
      "296 | 161 | 0.99\n",
      "297 | 162 | 0.99\n",
      "298 | 163 | 0.99\n",
      "299 | 164 | 1.0\n",
      "299 | 165 | 0.96\n",
      "300 | 164 | 0.97\n",
      "300 | 165 | 1.0\n",
      "300 | 299 | 0.97\n",
      "301 | 166 | 0.96\n",
      "302 | 167 | 0.98\n",
      "303 | 168 | 0.96\n",
      "304 | 169 | 0.98\n",
      "305 | 170 | 0.96\n",
      "306 | 171 | 0.99\n",
      "307 | 172 | 0.96\n",
      "307 | 174 | 0.96\n",
      "308 | 173 | 0.96\n",
      "309 | 172 | 0.96\n",
      "309 | 174 | 0.96\n",
      "309 | 307 | 1.0\n",
      "310 | 175 | 0.96\n",
      "311 | 176 | 0.98\n",
      "312 | 177 | 1.0\n",
      "317 | 181 | 0.96\n",
      "318 | 182 | 0.98\n",
      "319 | 183 | 0.98\n",
      "320 | 184 | 0.99\n",
      "321 | 185 | 0.99\n",
      "323 | 187 | 0.99\n",
      "324 | 188 | 0.98\n",
      "332 | 196 | 0.96\n",
      "333 | 197 | 0.98\n",
      "334 | 198 | 0.99\n",
      "335 | 199 | 0.96\n",
      "335 | 332 | 0.96\n",
      "338 | 202 | 0.99\n",
      "339 | 203 | 0.98\n",
      "340 | 204 | 0.99\n",
      "341 | 205 | 0.99\n",
      "342 | 74 | 1.0\n",
      "342 | 206 | 1.0\n",
      "342 | 209 | 1.0\n",
      "343 | 207 | 0.98\n",
      "344 | 208 | 0.96\n",
      "346 | 345 | 0.98\n",
      "347 | 74 | 1.0\n",
      "347 | 206 | 1.0\n",
      "347 | 209 | 1.0\n",
      "347 | 342 | 1.0\n",
      "348 | 210 | 0.95\n",
      "349 | 211 | 0.99\n",
      "350 | 212 | 0.99\n",
      "351 | 213 | 1.0\n",
      "352 | 214 | 0.98\n",
      "353 | 215 | 0.98\n",
      "354 | 216 | 0.97\n",
      "355 | 217 | 0.99\n",
      "356 | 218 | 0.95\n",
      "357 | 219 | 0.98\n",
      "358 | 85 | 0.99\n",
      "358 | 220 | 0.99\n",
      "359 | 221 | 0.98\n",
      "360 | 222 | 0.99\n",
      "361 | 223 | 0.98\n",
      "362 | 224 | 1.0\n",
      "363 | 225 | 0.97\n",
      "365 | 227 | 0.97\n",
      "366 | 228 | 0.97\n",
      "376 | 238 | 0.97\n",
      "377 | 239 | 0.96\n",
      "382 | 244 | 1.0\n",
      "382 | 246 | 0.96\n",
      "383 | 245 | 1.0\n",
      "383 | 246 | 0.98\n",
      "384 | 244 | 0.96\n",
      "384 | 245 | 0.98\n",
      "384 | 246 | 1.0\n",
      "384 | 382 | 0.96\n",
      "384 | 383 | 0.98\n",
      "386 | 248 | 1.0\n",
      "387 | 114 | 0.98\n",
      "387 | 249 | 1.0\n",
      "388 | 250 | 0.97\n",
      "389 | 251 | 1.0\n",
      "390 | 117 | 0.99\n",
      "390 | 252 | 1.0\n",
      "391 | 253 | 0.99\n",
      "392 | 254 | 0.99\n",
      "393 | 255 | 0.99\n",
      "405 | 267 | 0.99\n",
      "406 | 268 | 0.97\n",
      "407 | 269 | 0.96\n",
      "408 | 135 | 1.0\n",
      "409 | 136 | 1.0\n",
      "409 | 271 | 0.97\n",
      "410 | 137 | 1.0\n",
      "410 | 272 | 0.97\n",
      "411 | 138 | 1.0\n",
      "415 | 142 | 0.99\n",
      "415 | 277 | 0.97\n",
      "416 | 143 | 1.0\n",
      "417 | 144 | 0.99\n",
      "417 | 279 | 0.97\n",
      "420 | 147 | 1.0\n",
      "420 | 282 | 1.0\n",
      "421 | 16 | 0.95\n",
      "421 | 148 | 1.0\n",
      "421 | 152 | 0.98\n",
      "421 | 154 | 0.95\n",
      "421 | 283 | 1.0\n",
      "421 | 287 | 0.98\n",
      "421 | 289 | 0.95\n",
      "424 | 151 | 0.98\n",
      "424 | 286 | 0.97\n",
      "425 | 148 | 0.96\n",
      "425 | 152 | 0.98\n",
      "425 | 283 | 0.96\n",
      "425 | 287 | 0.97\n",
      "425 | 421 | 0.95\n",
      "426 | 153 | 1.0\n",
      "426 | 288 | 0.99\n",
      "427 | 148 | 0.95\n",
      "427 | 154 | 1.0\n",
      "427 | 283 | 0.95\n",
      "427 | 289 | 0.99\n",
      "427 | 421 | 0.97\n",
      "428 | 155 | 1.0\n",
      "428 | 290 | 0.96\n",
      "429 | 156 | 1.0\n",
      "429 | 291 | 0.99\n",
      "435 | 430 | 0.95\n",
      "435 | 434 | 0.99\n",
      "436 | 430 | 0.95\n",
      "436 | 434 | 0.99\n",
      "436 | 435 | 1.0\n",
      "437 | 166 | 0.99\n",
      "440 | 169 | 1.0\n",
      "440 | 304 | 0.98\n",
      "441 | 170 | 1.0\n",
      "441 | 305 | 0.95\n",
      "442 | 171 | 0.97\n",
      "442 | 306 | 0.96\n",
      "443 | 172 | 1.0\n",
      "443 | 174 | 1.0\n",
      "443 | 307 | 0.96\n",
      "443 | 309 | 0.96\n",
      "444 | 173 | 0.99\n",
      "444 | 308 | 0.95\n",
      "445 | 172 | 1.0\n",
      "445 | 174 | 1.0\n",
      "445 | 307 | 0.96\n",
      "445 | 309 | 0.96\n",
      "445 | 443 | 0.99\n",
      "446 | 175 | 1.0\n",
      "446 | 310 | 0.96\n",
      "447 | 176 | 1.0\n",
      "447 | 311 | 0.98\n",
      "448 | 177 | 1.0\n",
      "448 | 312 | 1.0\n",
      "452 | 180 | 0.99\n",
      "453 | 181 | 1.0\n",
      "453 | 317 | 0.96\n",
      "454 | 182 | 0.99\n",
      "454 | 318 | 0.97\n",
      "455 | 183 | 1.0\n",
      "455 | 319 | 0.98\n",
      "456 | 184 | 0.97\n",
      "456 | 320 | 0.96\n",
      "457 | 185 | 1.0\n",
      "457 | 321 | 0.99\n",
      "459 | 187 | 1.0\n",
      "459 | 323 | 0.99\n",
      "467 | 195 | 1.0\n",
      "467 | 331 | 0.95\n",
      "469 | 197 | 1.0\n",
      "469 | 333 | 0.99\n",
      "470 | 198 | 1.0\n",
      "470 | 334 | 0.98\n",
      "475 | 203 | 1.0\n",
      "475 | 339 | 0.99\n",
      "477 | 205 | 0.99\n",
      "477 | 341 | 0.99\n",
      "478 | 74 | 1.0\n",
      "478 | 206 | 1.0\n",
      "478 | 209 | 1.0\n",
      "478 | 342 | 1.0\n",
      "478 | 347 | 1.0\n",
      "479 | 207 | 1.0\n",
      "479 | 343 | 0.97\n",
      "490 | 218 | 0.98\n",
      "491 | 219 | 1.0\n",
      "491 | 357 | 0.97\n",
      "492 | 85 | 0.97\n",
      "492 | 220 | 1.0\n",
      "492 | 358 | 0.99\n",
      "493 | 221 | 1.0\n",
      "493 | 359 | 0.98\n",
      "494 | 222 | 1.0\n",
      "494 | 360 | 1.0\n",
      "495 | 223 | 1.0\n",
      "495 | 361 | 0.97\n",
      "497 | 225 | 0.99\n",
      "497 | 363 | 0.97\n",
      "516 | 244 | 1.0\n",
      "516 | 246 | 0.96\n",
      "516 | 382 | 1.0\n",
      "516 | 384 | 0.96\n",
      "517 | 244 | 0.95\n",
      "517 | 245 | 1.0\n",
      "517 | 246 | 0.98\n",
      "517 | 382 | 0.95\n",
      "517 | 383 | 1.0\n",
      "517 | 384 | 0.98\n",
      "517 | 516 | 0.95\n",
      "518 | 244 | 0.96\n",
      "518 | 245 | 0.98\n",
      "518 | 246 | 1.0\n",
      "518 | 382 | 0.96\n",
      "518 | 383 | 0.98\n",
      "518 | 384 | 1.0\n",
      "518 | 516 | 0.96\n",
      "518 | 517 | 0.98\n",
      "519 | 247 | 0.97\n",
      "519 | 385 | 0.96\n",
      "520 | 248 | 1.0\n",
      "520 | 386 | 1.0\n",
      "522 | 250 | 0.99\n",
      "522 | 388 | 0.96\n",
      "523 | 251 | 1.0\n",
      "523 | 389 | 1.0\n",
      "524 | 117 | 0.98\n",
      "524 | 252 | 1.0\n",
      "524 | 390 | 1.0\n",
      "525 | 253 | 1.0\n",
      "525 | 391 | 0.99\n",
      "526 | 254 | 1.0\n",
      "526 | 392 | 0.99\n",
      "527 | 255 | 1.0\n",
      "527 | 393 | 0.98\n",
      "539 | 267 | 1.0\n",
      "539 | 405 | 0.99\n",
      "540 | 268 | 1.0\n",
      "540 | 406 | 0.97\n",
      "541 | 269 | 0.97\n",
      "545 | 543 | 0.99\n",
      "548 | 547 | 0.99\n",
      "552 | 549 | 1.0\n",
      "553 | 550 | 0.99\n",
      "554 | 551 | 1.0\n",
      "556 | 550 | 1.0\n",
      "556 | 553 | 0.99\n",
      "557 | 551 | 1.0\n",
      "557 | 554 | 1.0\n",
      "561 | 559 | 0.98\n",
      "566 | 564 | 0.99\n",
      "567 | 565 | 0.99\n",
      "568 | 564 | 1.0\n",
      "568 | 566 | 0.99\n",
      "569 | 565 | 0.96\n",
      "569 | 567 | 0.96\n",
      "574 | 572 | 0.99\n",
      "575 | 573 | 0.98\n",
      "576 | 572 | 0.99\n",
      "576 | 574 | 0.99\n",
      "577 | 573 | 0.96\n",
      "580 | 579 | 0.99\n",
      "584 | 583 | 0.99\n",
      "585 | 583 | 1.0\n",
      "585 | 584 | 1.0\n",
      "588 | 587 | 0.97\n",
      "x_train shape : (1253, 269)\n",
      "y_train shape : (1253,)\n",
      "x_test shape : (157, 269)\n",
      "y_test shape : (157,)\n",
      "x_val shape : (157, 269)\n",
      "y_val shape : (157,)\n"
     ]
    }
   ],
   "source": [
    "data_pre = data_preprocess(data)\n",
    "X, y = split_x_y(data_pre)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y)\n",
    "X_train, X_val, X_test = standardization(X_train, X_val, X_test)\n",
    "y_train, y_val, y_test = y_change(y_train), y_change(y_val), y_change(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19336c44",
   "metadata": {
    "papermill": {
     "duration": 0.008027,
     "end_time": "2023-04-04T12:42:20.105021",
     "exception": false,
     "start_time": "2023-04-04T12:42:20.096994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tensorflos Keras Modeling\n",
    "- 32-16-8-4-2 1d layers\n",
    "- Activation : ReLU \n",
    "- Loss function : cross-entropy / Optimizer : Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac6483c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:20.132710Z",
     "iopub.status.busy": "2023-04-04T12:42:20.131479Z",
     "iopub.status.idle": "2023-04-04T12:42:20.298024Z",
     "shell.execute_reply": "2023-04-04T12:42:20.296817Z"
    },
    "papermill": {
     "duration": 0.181017,
     "end_time": "2023-04-04T12:42:20.301045",
     "exception": false,
     "start_time": "2023-04-04T12:42:20.120028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu',input_shape = (X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2, activation = 'softmax'),    \n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92017c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:20.320727Z",
     "iopub.status.busy": "2023-04-04T12:42:20.320043Z",
     "iopub.status.idle": "2023-04-04T12:42:41.802134Z",
     "shell.execute_reply": "2023-04-04T12:42:41.801019Z"
    },
    "papermill": {
     "duration": 21.495676,
     "end_time": "2023-04-04T12:42:41.805170",
     "exception": false,
     "start_time": "2023-04-04T12:42:20.309494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 0.3621 - val_loss: 0.2092\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1979 - val_loss: 0.1560\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1326\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.1058 - val_loss: 0.1131\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0964\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0881\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0851\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0829\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0834\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0747\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0791\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0800\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0810\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0836\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0765\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0765\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0777\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0764\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0778\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0772\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0759\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0763\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0767\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0762\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0769\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0777\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0779\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0791\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0792\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0766\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0768\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0745\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0739\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0750\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0683\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0706\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0718\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0717\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0724\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0725\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0718\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0704\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0671\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0663\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0656\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0659\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0658\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0664\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0668\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0671\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0675\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0678\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0686\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0693\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0696\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0668\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0670\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0618\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0608\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0611\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0609\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0613\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0592\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0594\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0581\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0591\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0577\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0566\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0554\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0567\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0574\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0580\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0583\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0487\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0524\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0543\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0548\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0553\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0554\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0557\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0560\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0563\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0565\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0567\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0570\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0572\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0574\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0576\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0579\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0581\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0585\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0587\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0590\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0595\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0596\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0597\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0598\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0600\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0602\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0591\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501e51b",
   "metadata": {
    "papermill": {
     "duration": 0.034533,
     "end_time": "2023-04-04T12:42:41.874393",
     "exception": false,
     "start_time": "2023-04-04T12:42:41.839860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed61d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:41.942826Z",
     "iopub.status.busy": "2023-04-04T12:42:41.942329Z",
     "iopub.status.idle": "2023-04-04T12:42:41.952067Z",
     "shell.execute_reply": "2023-04-04T12:42:41.950583Z"
    },
    "papermill": {
     "duration": 0.047077,
     "end_time": "2023-04-04T12:42:41.954600",
     "exception": false,
     "start_time": "2023-04-04T12:42:41.907523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_metric(x_test, model):\n",
    "    y_pred = np.argmax(model.predict(x_test), axis = 1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    tp = cm[0,0]\n",
    "    fn = cm[0,1]\n",
    "    fp = cm[1,0]\n",
    "    tn = cm[1,1]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*precision*recall / (precision + recall)\n",
    "    acc = (tp+tn) / (tp+fn+fp+tn)\n",
    "    print('precision : ', precision)\n",
    "    print('recall : ', recall)\n",
    "    print('f1 : ', f1)\n",
    "    print('acc : ', acc)\n",
    "    \n",
    "    return cm, precision, recall, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823e510b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:42.023745Z",
     "iopub.status.busy": "2023-04-04T12:42:42.023198Z",
     "iopub.status.idle": "2023-04-04T12:42:42.204053Z",
     "shell.execute_reply": "2023-04-04T12:42:42.202549Z"
    },
    "papermill": {
     "duration": 0.21872,
     "end_time": "2023-04-04T12:42:42.206453",
     "exception": false,
     "start_time": "2023-04-04T12:42:41.987733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "[[141   0]\n",
      " [ 12   4]]\n",
      "precision :  0.9215686274509803\n",
      "recall :  1.0\n",
      "f1 :  0.9591836734693878\n",
      "acc :  0.9235668789808917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[141,   0],\n",
       "        [ 12,   4]]),\n",
       " 0.9215686274509803,\n",
       " 1.0,\n",
       " 0.9591836734693878,\n",
       " 0.9235668789808917)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metric(X_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2b84f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-04T12:42:42.276467Z",
     "iopub.status.busy": "2023-04-04T12:42:42.276032Z",
     "iopub.status.idle": "2023-04-04T12:42:42.661710Z",
     "shell.execute_reply": "2023-04-04T12:42:42.660581Z"
    },
    "papermill": {
     "duration": 0.424567,
     "end_time": "2023-04-04T12:42:42.664256",
     "exception": false,
     "start_time": "2023-04-04T12:42:42.239689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis =1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm/np.sum(cm),fmt='.2%', annot = True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.828852,
   "end_time": "2023-04-04T12:42:46.098800",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-04T12:41:42.269948",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
